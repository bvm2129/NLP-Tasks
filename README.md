# NLP-Tasks

Here's a lyrical little brief on the core NLP tasks, each one a different petal on this blooming flower:

ğŸŒ¿ 1. Text Classification What: Categorizing text into labels (e.g., spam or not spam, news categories).

Example: Email spam detection, sentiment analysis.

Model Used: BERT, RoBERTa.

ğŸª¶ 2. Named Entity Recognition (NER) What: Detecting proper nouns like names, places, brands.

Example: â€œSachin Tendulkar played for Indiaâ€ â†’ [Person: Sachin Tendulkar], [Country: India]

ğŸ’Œ 3. Sentiment Analysis What: Understanding emotions in text (positive, negative, neutral).

Example: "I love this song" â†’ Positive.

ğŸ§  4. Text Generation What: Generating new text given a prompt.

Example: Writing poems, code, emails â€” like what GPT does!

ğŸ§¾ 5. Question Answering (QA) What: Answering questions based on a given passage or document.

Example: SQuAD dataset, chatbot-style queries.

ğŸ” 6. Machine Translation What: Translating from one language to another.

Example: English to Hindi â†’ "Good morning" â†’ "à¤¶à¥à¤­ à¤ªà¥à¤°à¤­à¤¾à¤¤"

ğŸ§¹ 7. Text Summarization What: Creating shorter versions of long texts.

Types: Extractive (pulls from text), Abstractive (rewrites it).

Example: TL;DR of a news article.

ğŸ”„ 8. Text-to-Text Tasks What: Converting text from one form to another.

Example: Grammar correction, converting passive to active voice.

ğŸ§™ 9. Dialogue Systems / Chatbots What: Carrying on a conversation.

Example: Your Aadhya here! ğŸ˜Š Built with LLMs trained on dialogue.

âœ¨ Bonus: Core Techniques Behind NLP Tokenization: Breaking text into words/tokens.

Embeddings: Converting words to vectors.

Transformers: The heart of modern NLP (BERT, GPT, T5, etc.)
